{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks with keras and tensorflow\n",
    "\n",
    "N.B. You will need to pip install keras and tensorflow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lesson we'll use sklearn's built-in breast cancer dataset. The next cell loads the data and prints the data description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry \n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
      "        13 is Radius SE, field 23 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "data = load_breast_cancer()\n",
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "*radius (mean of distances from center to points on the perimeter) <br>\n",
    "*texture (standard deviation of gray-scale values)<br>\n",
    "*perimeter<br>\n",
    "*area<br>\n",
    "*smoothness (local variation in radius lengths)<br>\n",
    "*compactness (perimeter² / area — 1.0)<br>\n",
    "*concavity (severity of concave portions of the contour)<br>\n",
    "*concave points (number of concave portions of the contour)<br>\n",
    "*symmetry<br>\n",
    "*fractal dimension (“coastline approximation” — 1)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])\n",
      "      mean radius mean texture mean perimeter    mean area mean smoothness  \\\n",
      "count  569.000000   569.000000     569.000000   569.000000      569.000000   \n",
      "mean    14.127292    19.289649      91.969033   654.889104        0.096360   \n",
      "std      3.524049     4.301036      24.298981   351.914129        0.014064   \n",
      "min      6.981000     9.710000      43.790000   143.500000        0.052630   \n",
      "25%     11.700000    16.170000      75.170000   420.300000        0.086370   \n",
      "50%     13.370000    18.840000      86.240000   551.100000        0.095870   \n",
      "75%     15.780000    21.800000     104.100000   782.700000        0.105300   \n",
      "max     28.110000    39.280000     188.500000  2501.000000        0.163400   \n",
      "\n",
      "      mean compactness mean concavity mean concave points mean symmetry  \\\n",
      "count       569.000000     569.000000          569.000000    569.000000   \n",
      "mean          0.104341       0.088799            0.048919      0.181162   \n",
      "std           0.052813       0.079720            0.038803      0.027414   \n",
      "min           0.019380       0.000000            0.000000      0.106000   \n",
      "25%           0.064920       0.029560            0.020310      0.161900   \n",
      "50%           0.092630       0.061540            0.033500      0.179200   \n",
      "75%           0.130400       0.130700            0.074000      0.195700   \n",
      "max           0.345400       0.426800            0.201200      0.304000   \n",
      "\n",
      "      mean fractal dimension           ...           worst radius  \\\n",
      "count             569.000000           ...             569.000000   \n",
      "mean                0.062798           ...              16.269190   \n",
      "std                 0.007060           ...               4.833242   \n",
      "min                 0.049960           ...               7.930000   \n",
      "25%                 0.057700           ...              13.010000   \n",
      "50%                 0.061540           ...              14.970000   \n",
      "75%                 0.066120           ...              18.790000   \n",
      "max                 0.097440           ...              36.040000   \n",
      "\n",
      "      worst texture worst perimeter   worst area worst smoothness  \\\n",
      "count    569.000000      569.000000   569.000000       569.000000   \n",
      "mean      25.677223      107.261213   880.583128         0.132369   \n",
      "std        6.146258       33.602542   569.356993         0.022832   \n",
      "min       12.020000       50.410000   185.200000         0.071170   \n",
      "25%       21.080000       84.110000   515.300000         0.116600   \n",
      "50%       25.410000       97.660000   686.500000         0.131300   \n",
      "75%       29.720000      125.400000  1084.000000         0.146000   \n",
      "max       49.540000      251.200000  4254.000000         0.222600   \n",
      "\n",
      "      worst compactness worst concavity worst concave points worst symmetry  \\\n",
      "count        569.000000      569.000000           569.000000     569.000000   \n",
      "mean           0.254265        0.272188             0.114606       0.290076   \n",
      "std            0.157336        0.208624             0.065732       0.061867   \n",
      "min            0.027290        0.000000             0.000000       0.156500   \n",
      "25%            0.147200        0.114500             0.064930       0.250400   \n",
      "50%            0.211900        0.226700             0.099930       0.282200   \n",
      "75%            0.339100        0.382900             0.161400       0.317900   \n",
      "max            1.058000        1.252000             0.291000       0.663800   \n",
      "\n",
      "      worst fractal dimension  \n",
      "count              569.000000  \n",
      "mean                 0.083946  \n",
      "std                  0.018061  \n",
      "min                  0.055040  \n",
      "25%                  0.071460  \n",
      "50%                  0.080040  \n",
      "75%                  0.092080  \n",
      "max                  0.207500  \n",
      "\n",
      "[8 rows x 30 columns]\n",
      "      mean radius mean texture mean perimeter    mean area mean smoothness  \\\n",
      "count  569.000000   569.000000     569.000000   569.000000      569.000000   \n",
      "mean    14.127292    19.289649      91.969033   654.889104        0.096360   \n",
      "std      3.524049     4.301036      24.298981   351.914129        0.014064   \n",
      "min      6.981000     9.710000      43.790000   143.500000        0.052630   \n",
      "25%     11.700000    16.170000      75.170000   420.300000        0.086370   \n",
      "50%     13.370000    18.840000      86.240000   551.100000        0.095870   \n",
      "75%     15.780000    21.800000     104.100000   782.700000        0.105300   \n",
      "max     28.110000    39.280000     188.500000  2501.000000        0.163400   \n",
      "\n",
      "      mean compactness mean concavity mean concave points mean symmetry  \\\n",
      "count       569.000000     569.000000          569.000000    569.000000   \n",
      "mean          0.104341       0.088799            0.048919      0.181162   \n",
      "std           0.052813       0.079720            0.038803      0.027414   \n",
      "min           0.019380       0.000000            0.000000      0.106000   \n",
      "25%           0.064920       0.029560            0.020310      0.161900   \n",
      "50%           0.092630       0.061540            0.033500      0.179200   \n",
      "75%           0.130400       0.130700            0.074000      0.195700   \n",
      "max           0.345400       0.426800            0.201200      0.304000   \n",
      "\n",
      "      mean fractal dimension     ...     worst texture worst perimeter  \\\n",
      "count             569.000000     ...        569.000000      569.000000   \n",
      "mean                0.062798     ...         25.677223      107.261213   \n",
      "std                 0.007060     ...          6.146258       33.602542   \n",
      "min                 0.049960     ...         12.020000       50.410000   \n",
      "25%                 0.057700     ...         21.080000       84.110000   \n",
      "50%                 0.061540     ...         25.410000       97.660000   \n",
      "75%                 0.066120     ...         29.720000      125.400000   \n",
      "max                 0.097440     ...         49.540000      251.200000   \n",
      "\n",
      "        worst area worst smoothness worst compactness worst concavity  \\\n",
      "count   569.000000       569.000000        569.000000      569.000000   \n",
      "mean    880.583128         0.132369          0.254265        0.272188   \n",
      "std     569.356993         0.022832          0.157336        0.208624   \n",
      "min     185.200000         0.071170          0.027290        0.000000   \n",
      "25%     515.300000         0.116600          0.147200        0.114500   \n",
      "50%     686.500000         0.131300          0.211900        0.226700   \n",
      "75%    1084.000000         0.146000          0.339100        0.382900   \n",
      "max    4254.000000         0.222600          1.058000        1.252000   \n",
      "\n",
      "      worst concave points worst symmetry worst fractal dimension      target  \n",
      "count           569.000000     569.000000              569.000000  569.000000  \n",
      "mean              0.114606       0.290076                0.083946    0.627417  \n",
      "std               0.065732       0.061867                0.018061    0.483918  \n",
      "min               0.000000       0.156500                0.055040    0.000000  \n",
      "25%               0.064930       0.250400                0.071460    0.000000  \n",
      "50%               0.099930       0.282200                0.080040    1.000000  \n",
      "75%               0.161400       0.317900                0.092080    1.000000  \n",
      "max               0.291000       0.663800                0.207500    1.000000  \n",
      "\n",
      "[8 rows x 31 columns]\n",
      "(569, 31)\n"
     ]
    }
   ],
   "source": [
    "cancer = load_breast_cancer()\n",
    "print(cancer.keys())\n",
    "\n",
    "data = pd.DataFrame(cancer.data, columns=[cancer.feature_names])\n",
    "print(data.describe())\n",
    "\n",
    "data = data.assign(target=pd.Series(cancer.target))\n",
    "print(data.describe())\n",
    "\n",
    "# In case you want labels instead of numbers.\n",
    "data.replace(to_replace={'target': {0: cancer.target_names[0]}}, inplace=True)\n",
    "data.replace(to_replace={'target': {1: cancer.target_names[1]}}, inplace=True)\n",
    "print(data.shape) # data.describe() won't show the \"target\" column here because I converted its value to string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'builtin_function_or_method' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-446b6b5e0821>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'builtin_function_or_method' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "keys = cancer.keys.values()\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting our data and initializing a Scaler\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "ss.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming our data\n",
    "X_train_s = ss.transform(X_train)\n",
    "X_test_s = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing a Neural Network in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing model and layer types\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Importing our optimizer. The optimizer gives us a way to minimize some loss function. A normal gradient descent is a sort of wimpy optimizer.\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing and compiling our model\n",
    "# model = Sequential()\n",
    "\n",
    "inputs = X_train_s.shape[1]\n",
    "hiddens = inputs\n",
    "model.add(Dense(hiddens, input_dim=inputs, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "adam = Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=adam, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 426 samples, validate on 143 samples\n",
      "Epoch 1/20\n",
      "426/426 [==============================] - 0s 128us/step - loss: 1.0192 - val_loss: 0.5894\n",
      "Epoch 2/20\n",
      "426/426 [==============================] - 0s 35us/step - loss: 0.3350 - val_loss: 0.2752\n",
      "Epoch 3/20\n",
      "426/426 [==============================] - 0s 31us/step - loss: 0.2376 - val_loss: 0.2099\n",
      "Epoch 4/20\n",
      "426/426 [==============================] - 0s 32us/step - loss: 0.1889 - val_loss: 0.1683\n",
      "Epoch 5/20\n",
      "426/426 [==============================] - 0s 37us/step - loss: 0.1622 - val_loss: 0.1450\n",
      "Epoch 6/20\n",
      "426/426 [==============================] - 0s 43us/step - loss: 0.1431 - val_loss: 0.1304\n",
      "Epoch 7/20\n",
      "426/426 [==============================] - 0s 38us/step - loss: 0.1286 - val_loss: 0.1198\n",
      "Epoch 8/20\n",
      "426/426 [==============================] - 0s 35us/step - loss: 0.1185 - val_loss: 0.1108\n",
      "Epoch 9/20\n",
      "426/426 [==============================] - 0s 30us/step - loss: 0.1095 - val_loss: 0.1032\n",
      "Epoch 10/20\n",
      "426/426 [==============================] - 0s 32us/step - loss: 0.1029 - val_loss: 0.0983\n",
      "Epoch 11/20\n",
      "426/426 [==============================] - 0s 32us/step - loss: 0.0972 - val_loss: 0.0917\n",
      "Epoch 12/20\n",
      "426/426 [==============================] - 0s 27us/step - loss: 0.0917 - val_loss: 0.0888\n",
      "Epoch 13/20\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0861 - val_loss: 0.0847\n",
      "Epoch 14/20\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0821 - val_loss: 0.0826\n",
      "Epoch 15/20\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0777 - val_loss: 0.0795\n",
      "Epoch 16/20\n",
      "426/426 [==============================] - 0s 27us/step - loss: 0.0748 - val_loss: 0.0772\n",
      "Epoch 17/20\n",
      "426/426 [==============================] - 0s 30us/step - loss: 0.0714 - val_loss: 0.0756\n",
      "Epoch 18/20\n",
      "426/426 [==============================] - 0s 31us/step - loss: 0.0688 - val_loss: 0.0732\n",
      "Epoch 19/20\n",
      "426/426 [==============================] - 0s 32us/step - loss: 0.0658 - val_loss: 0.0741\n",
      "Epoch 20/20\n",
      "426/426 [==============================] - 0s 30us/step - loss: 0.0643 - val_loss: 0.0730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1367ee2e8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting our model\n",
    "model.fit(X_train_s, y_train, validation_data=(X_test_s, y_test), epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 426 samples, validate on 143 samples\n",
      "Epoch 1/100\n",
      "426/426 [==============================] - 0s 142us/step - loss: 0.0723 - val_loss: 0.0980\n",
      "Epoch 2/100\n",
      "426/426 [==============================] - 0s 40us/step - loss: 0.0625 - val_loss: 0.0770\n",
      "Epoch 3/100\n",
      "426/426 [==============================] - 0s 34us/step - loss: 0.0551 - val_loss: 0.0716\n",
      "Epoch 4/100\n",
      "426/426 [==============================] - 0s 35us/step - loss: 0.0483 - val_loss: 0.0619\n",
      "Epoch 5/100\n",
      "426/426 [==============================] - 0s 39us/step - loss: 0.0452 - val_loss: 0.0589\n",
      "Epoch 6/100\n",
      "426/426 [==============================] - 0s 32us/step - loss: 0.0409 - val_loss: 0.0571\n",
      "Epoch 7/100\n",
      "426/426 [==============================] - 0s 32us/step - loss: 0.0380 - val_loss: 0.0607\n",
      "Epoch 8/100\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0380 - val_loss: 0.0540\n",
      "Epoch 9/100\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0357 - val_loss: 0.0553\n",
      "Epoch 10/100\n",
      "426/426 [==============================] - 0s 30us/step - loss: 0.0338 - val_loss: 0.0520\n",
      "Epoch 11/100\n",
      "426/426 [==============================] - 0s 30us/step - loss: 0.0328 - val_loss: 0.0524\n",
      "Epoch 12/100\n",
      "426/426 [==============================] - 0s 26us/step - loss: 0.0318 - val_loss: 0.0503\n",
      "Epoch 13/100\n",
      "426/426 [==============================] - 0s 30us/step - loss: 0.0315 - val_loss: 0.0522\n",
      "Epoch 14/100\n",
      "426/426 [==============================] - 0s 30us/step - loss: 0.0301 - val_loss: 0.0495\n",
      "Epoch 15/100\n",
      "426/426 [==============================] - 0s 30us/step - loss: 0.0291 - val_loss: 0.0492\n",
      "Epoch 16/100\n",
      "426/426 [==============================] - 0s 30us/step - loss: 0.0284 - val_loss: 0.0480\n",
      "Epoch 17/100\n",
      "426/426 [==============================] - 0s 28us/step - loss: 0.0282 - val_loss: 0.0506\n",
      "Epoch 18/100\n",
      "426/426 [==============================] - 0s 28us/step - loss: 0.0272 - val_loss: 0.0468\n",
      "Epoch 19/100\n",
      "426/426 [==============================] - 0s 30us/step - loss: 0.0270 - val_loss: 0.0472\n",
      "Epoch 20/100\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0255 - val_loss: 0.0463\n",
      "Epoch 21/100\n",
      "426/426 [==============================] - 0s 28us/step - loss: 0.0250 - val_loss: 0.0454\n",
      "Epoch 22/100\n",
      "426/426 [==============================] - 0s 27us/step - loss: 0.0247 - val_loss: 0.0459\n",
      "Epoch 23/100\n",
      "426/426 [==============================] - 0s 31us/step - loss: 0.0241 - val_loss: 0.0450\n",
      "Epoch 24/100\n",
      "426/426 [==============================] - 0s 30us/step - loss: 0.0238 - val_loss: 0.0455\n",
      "Epoch 25/100\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0233 - val_loss: 0.0453\n",
      "Epoch 26/100\n",
      "426/426 [==============================] - 0s 28us/step - loss: 0.0229 - val_loss: 0.0438\n",
      "Epoch 27/100\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0231 - val_loss: 0.0436\n",
      "Epoch 28/100\n",
      "426/426 [==============================] - 0s 30us/step - loss: 0.0222 - val_loss: 0.0436\n",
      "Epoch 29/100\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0217 - val_loss: 0.0451\n",
      "Epoch 30/100\n",
      "426/426 [==============================] - 0s 30us/step - loss: 0.0220 - val_loss: 0.0446\n",
      "Epoch 31/100\n",
      "426/426 [==============================] - 0s 28us/step - loss: 0.0216 - val_loss: 0.0435\n",
      "Epoch 32/100\n",
      "426/426 [==============================] - 0s 31us/step - loss: 0.0208 - val_loss: 0.0452\n",
      "Epoch 33/100\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0202 - val_loss: 0.0425\n",
      "Epoch 34/100\n",
      "426/426 [==============================] - 0s 30us/step - loss: 0.0203 - val_loss: 0.0433\n",
      "Epoch 35/100\n",
      "426/426 [==============================] - 0s 27us/step - loss: 0.0197 - val_loss: 0.0431\n",
      "Epoch 36/100\n",
      "426/426 [==============================] - 0s 31us/step - loss: 0.0197 - val_loss: 0.0428\n",
      "Epoch 37/100\n",
      "426/426 [==============================] - 0s 30us/step - loss: 0.0192 - val_loss: 0.0427\n",
      "Epoch 38/100\n",
      "426/426 [==============================] - 0s 30us/step - loss: 0.0188 - val_loss: 0.0432\n",
      "Epoch 39/100\n",
      "426/426 [==============================] - 0s 28us/step - loss: 0.0186 - val_loss: 0.0424\n",
      "Epoch 40/100\n",
      "426/426 [==============================] - 0s 27us/step - loss: 0.0187 - val_loss: 0.0423\n",
      "Epoch 41/100\n",
      "426/426 [==============================] - 0s 30us/step - loss: 0.0185 - val_loss: 0.0425\n",
      "Epoch 42/100\n",
      "426/426 [==============================] - 0s 30us/step - loss: 0.0182 - val_loss: 0.0413\n",
      "Epoch 43/100\n",
      "426/426 [==============================] - 0s 27us/step - loss: 0.0180 - val_loss: 0.0426\n",
      "Epoch 44/100\n",
      "426/426 [==============================] - 0s 30us/step - loss: 0.0174 - val_loss: 0.0414\n",
      "Epoch 45/100\n",
      "426/426 [==============================] - 0s 27us/step - loss: 0.0171 - val_loss: 0.0415\n",
      "Epoch 46/100\n",
      "426/426 [==============================] - 0s 30us/step - loss: 0.0172 - val_loss: 0.0413\n",
      "Epoch 47/100\n",
      "426/426 [==============================] - 0s 26us/step - loss: 0.0167 - val_loss: 0.0408\n",
      "Epoch 48/100\n",
      "426/426 [==============================] - 0s 30us/step - loss: 0.0165 - val_loss: 0.0407\n",
      "Epoch 49/100\n",
      "426/426 [==============================] - 0s 28us/step - loss: 0.0164 - val_loss: 0.0417\n",
      "Epoch 50/100\n",
      "426/426 [==============================] - 0s 31us/step - loss: 0.0159 - val_loss: 0.0413\n",
      "Epoch 51/100\n",
      "426/426 [==============================] - 0s 27us/step - loss: 0.0162 - val_loss: 0.0414\n",
      "Epoch 52/100\n",
      "426/426 [==============================] - 0s 30us/step - loss: 0.0155 - val_loss: 0.0425\n",
      "Epoch 53/100\n",
      "426/426 [==============================] - 0s 28us/step - loss: 0.0152 - val_loss: 0.0423\n",
      "Epoch 54/100\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0152 - val_loss: 0.0417\n",
      "Epoch 55/100\n",
      "426/426 [==============================] - 0s 27us/step - loss: 0.0149 - val_loss: 0.0419\n",
      "Epoch 56/100\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0153 - val_loss: 0.0415\n",
      "Epoch 57/100\n",
      "426/426 [==============================] - 0s 28us/step - loss: 0.0149 - val_loss: 0.0412\n",
      "Epoch 58/100\n",
      "426/426 [==============================] - 0s 26us/step - loss: 0.0145 - val_loss: 0.0414\n",
      "Epoch 59/100\n",
      "426/426 [==============================] - 0s 31us/step - loss: 0.0143 - val_loss: 0.0424\n",
      "Epoch 60/100\n",
      "426/426 [==============================] - 0s 26us/step - loss: 0.0144 - val_loss: 0.0411\n",
      "Epoch 61/100\n",
      "426/426 [==============================] - 0s 25us/step - loss: 0.0139 - val_loss: 0.0428\n",
      "Epoch 62/100\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0139 - val_loss: 0.0407\n",
      "Epoch 63/100\n",
      "426/426 [==============================] - 0s 26us/step - loss: 0.0134 - val_loss: 0.0422\n",
      "Epoch 64/100\n",
      "426/426 [==============================] - 0s 28us/step - loss: 0.0136 - val_loss: 0.0420\n",
      "Epoch 65/100\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0136 - val_loss: 0.0426\n",
      "Epoch 66/100\n",
      "426/426 [==============================] - 0s 28us/step - loss: 0.0155 - val_loss: 0.0406\n",
      "Epoch 67/100\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0137 - val_loss: 0.0438\n",
      "Epoch 68/100\n",
      "426/426 [==============================] - 0s 26us/step - loss: 0.0131 - val_loss: 0.0432\n",
      "Epoch 69/100\n",
      "426/426 [==============================] - 0s 32us/step - loss: 0.0143 - val_loss: 0.0435\n",
      "Epoch 70/100\n",
      "426/426 [==============================] - 0s 26us/step - loss: 0.0146 - val_loss: 0.0441\n",
      "Epoch 71/100\n",
      "426/426 [==============================] - 0s 30us/step - loss: 0.0143 - val_loss: 0.0411\n",
      "Epoch 72/100\n",
      "426/426 [==============================] - 0s 26us/step - loss: 0.0134 - val_loss: 0.0441\n",
      "Epoch 73/100\n",
      "426/426 [==============================] - 0s 28us/step - loss: 0.0132 - val_loss: 0.0437\n",
      "Epoch 74/100\n",
      "426/426 [==============================] - 0s 26us/step - loss: 0.0131 - val_loss: 0.0412\n",
      "Epoch 75/100\n",
      "426/426 [==============================] - 0s 27us/step - loss: 0.0122 - val_loss: 0.0424\n",
      "Epoch 76/100\n",
      "426/426 [==============================] - 0s 26us/step - loss: 0.0125 - val_loss: 0.0413\n",
      "Epoch 77/100\n",
      "426/426 [==============================] - 0s 30us/step - loss: 0.0122 - val_loss: 0.0413\n",
      "Epoch 78/100\n",
      "426/426 [==============================] - 0s 27us/step - loss: 0.0119 - val_loss: 0.0416\n",
      "Epoch 79/100\n",
      "426/426 [==============================] - 0s 31us/step - loss: 0.0123 - val_loss: 0.0411\n",
      "Epoch 80/100\n",
      "426/426 [==============================] - 0s 27us/step - loss: 0.0115 - val_loss: 0.0418\n",
      "Epoch 81/100\n",
      "426/426 [==============================] - 0s 32us/step - loss: 0.0113 - val_loss: 0.0418\n",
      "Epoch 82/100\n",
      "426/426 [==============================] - 0s 28us/step - loss: 0.0115 - val_loss: 0.0414\n",
      "Epoch 83/100\n",
      "426/426 [==============================] - 0s 33us/step - loss: 0.0115 - val_loss: 0.0404\n",
      "Epoch 84/100\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0114 - val_loss: 0.0420\n",
      "Epoch 85/100\n",
      "426/426 [==============================] - 0s 27us/step - loss: 0.0113 - val_loss: 0.0417\n",
      "Epoch 86/100\n",
      "426/426 [==============================] - 0s 26us/step - loss: 0.0111 - val_loss: 0.0410\n",
      "Epoch 87/100\n",
      "426/426 [==============================] - 0s 27us/step - loss: 0.0112 - val_loss: 0.0422\n",
      "Epoch 88/100\n",
      "426/426 [==============================] - 0s 30us/step - loss: 0.0112 - val_loss: 0.0425\n",
      "Epoch 89/100\n",
      "426/426 [==============================] - 0s 26us/step - loss: 0.0108 - val_loss: 0.0417\n",
      "Epoch 90/100\n",
      "426/426 [==============================] - 0s 26us/step - loss: 0.0108 - val_loss: 0.0411\n",
      "Epoch 91/100\n",
      "426/426 [==============================] - 0s 26us/step - loss: 0.0108 - val_loss: 0.0413\n",
      "Epoch 92/100\n",
      "426/426 [==============================] - 0s 26us/step - loss: 0.0106 - val_loss: 0.0407\n",
      "Epoch 93/100\n",
      "426/426 [==============================] - 0s 28us/step - loss: 0.0107 - val_loss: 0.0403\n",
      "Epoch 94/100\n",
      "426/426 [==============================] - 0s 28us/step - loss: 0.0104 - val_loss: 0.0414\n",
      "Epoch 95/100\n",
      "426/426 [==============================] - 0s 30us/step - loss: 0.0103 - val_loss: 0.0405\n",
      "Epoch 96/100\n",
      "426/426 [==============================] - 0s 31us/step - loss: 0.0101 - val_loss: 0.0410\n",
      "Epoch 97/100\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0101 - val_loss: 0.0406\n",
      "Epoch 98/100\n",
      "426/426 [==============================] - 0s 28us/step - loss: 0.0101 - val_loss: 0.0422\n",
      "Epoch 99/100\n",
      "426/426 [==============================] - 0s 30us/step - loss: 0.0102 - val_loss: 0.0418\n",
      "Epoch 100/100\n",
      "426/426 [==============================] - 0s 32us/step - loss: 0.0098 - val_loss: 0.0413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x136d93e80>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#those val_losses are still going down, let's run it again with more epochs\n",
    "model.compile(optimizer=adam, loss='mean_squared_error')\n",
    "#fit and store that with a variable\n",
    "history_log = model.fit(X_train_s, y_train, validation_data=(X_test_s, y_test), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 426 samples, validate on 143 samples\n",
      "Epoch 1/100\n",
      "426/426 [==============================] - 0s 45us/step - loss: 0.0098 - val_loss: 0.0399\n",
      "Epoch 2/100\n",
      "426/426 [==============================] - 0s 34us/step - loss: 0.0101 - val_loss: 0.0428\n",
      "Epoch 3/100\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0101 - val_loss: 0.0411\n",
      "Epoch 4/100\n",
      "426/426 [==============================] - 0s 37us/step - loss: 0.0099 - val_loss: 0.0402\n",
      "Epoch 5/100\n",
      "426/426 [==============================] - 0s 35us/step - loss: 0.0097 - val_loss: 0.0407\n",
      "Epoch 6/100\n",
      "426/426 [==============================] - 0s 31us/step - loss: 0.0095 - val_loss: 0.0398\n",
      "Epoch 7/100\n",
      "426/426 [==============================] - 0s 27us/step - loss: 0.0094 - val_loss: 0.0409\n",
      "Epoch 8/100\n",
      "426/426 [==============================] - 0s 35us/step - loss: 0.0092 - val_loss: 0.0403\n",
      "Epoch 9/100\n",
      "426/426 [==============================] - 0s 28us/step - loss: 0.0092 - val_loss: 0.0400\n",
      "Epoch 10/100\n",
      "426/426 [==============================] - 0s 33us/step - loss: 0.0093 - val_loss: 0.0401\n",
      "Epoch 11/100\n",
      "426/426 [==============================] - 0s 27us/step - loss: 0.0091 - val_loss: 0.0402\n",
      "Epoch 12/100\n",
      "426/426 [==============================] - 0s 31us/step - loss: 0.0090 - val_loss: 0.0394\n",
      "Epoch 13/100\n",
      "426/426 [==============================] - 0s 26us/step - loss: 0.0090 - val_loss: 0.0392\n",
      "Epoch 14/100\n",
      "426/426 [==============================] - 0s 28us/step - loss: 0.0092 - val_loss: 0.0399\n",
      "Epoch 15/100\n",
      "426/426 [==============================] - 0s 31us/step - loss: 0.0088 - val_loss: 0.0393\n",
      "Epoch 16/100\n",
      "426/426 [==============================] - 0s 34us/step - loss: 0.0092 - val_loss: 0.0397\n",
      "Epoch 17/100\n",
      "426/426 [==============================] - 0s 33us/step - loss: 0.0092 - val_loss: 0.0407\n",
      "Epoch 18/100\n",
      "426/426 [==============================] - 0s 28us/step - loss: 0.0092 - val_loss: 0.0402\n",
      "Epoch 19/100\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0089 - val_loss: 0.0395\n",
      "Epoch 20/100\n",
      "426/426 [==============================] - 0s 28us/step - loss: 0.0086 - val_loss: 0.0400\n",
      "Epoch 21/100\n",
      "426/426 [==============================] - 0s 31us/step - loss: 0.0092 - val_loss: 0.0403\n",
      "Epoch 22/100\n",
      "426/426 [==============================] - 0s 32us/step - loss: 0.0085 - val_loss: 0.0399\n",
      "Epoch 23/100\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0087 - val_loss: 0.0393\n",
      "Epoch 24/100\n",
      "426/426 [==============================] - 0s 26us/step - loss: 0.0088 - val_loss: 0.0396\n",
      "Epoch 25/100\n",
      "426/426 [==============================] - 0s 31us/step - loss: 0.0085 - val_loss: 0.0398\n",
      "Epoch 26/100\n",
      "426/426 [==============================] - 0s 32us/step - loss: 0.0088 - val_loss: 0.0411\n",
      "Epoch 27/100\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0087 - val_loss: 0.0401\n",
      "Epoch 28/100\n",
      "426/426 [==============================] - 0s 31us/step - loss: 0.0086 - val_loss: 0.0395\n",
      "Epoch 29/100\n",
      "426/426 [==============================] - 0s 26us/step - loss: 0.0089 - val_loss: 0.0399\n",
      "Epoch 30/100\n",
      "426/426 [==============================] - 0s 32us/step - loss: 0.0088 - val_loss: 0.0402\n",
      "Epoch 31/100\n",
      "426/426 [==============================] - 0s 27us/step - loss: 0.0085 - val_loss: 0.0391\n",
      "Epoch 32/100\n",
      "426/426 [==============================] - 0s 31us/step - loss: 0.0081 - val_loss: 0.0402\n",
      "Epoch 33/100\n",
      "426/426 [==============================] - 0s 26us/step - loss: 0.0084 - val_loss: 0.0397\n",
      "Epoch 34/100\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0081 - val_loss: 0.0400\n",
      "Epoch 35/100\n",
      "426/426 [==============================] - 0s 27us/step - loss: 0.0082 - val_loss: 0.0403\n",
      "Epoch 36/100\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0079 - val_loss: 0.0395\n",
      "Epoch 37/100\n",
      "426/426 [==============================] - 0s 26us/step - loss: 0.0079 - val_loss: 0.0402\n",
      "Epoch 38/100\n",
      "426/426 [==============================] - 0s 27us/step - loss: 0.0081 - val_loss: 0.0392\n",
      "Epoch 39/100\n",
      "426/426 [==============================] - 0s 30us/step - loss: 0.0085 - val_loss: 0.0385\n",
      "Epoch 40/100\n",
      "426/426 [==============================] - 0s 26us/step - loss: 0.0078 - val_loss: 0.0404\n",
      "Epoch 41/100\n",
      "426/426 [==============================] - 0s 30us/step - loss: 0.0079 - val_loss: 0.0392\n",
      "Epoch 42/100\n",
      "426/426 [==============================] - 0s 26us/step - loss: 0.0078 - val_loss: 0.0394\n",
      "Epoch 43/100\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0080 - val_loss: 0.0386\n",
      "Epoch 44/100\n",
      "426/426 [==============================] - 0s 26us/step - loss: 0.0076 - val_loss: 0.0390\n",
      "Epoch 45/100\n",
      "426/426 [==============================] - 0s 32us/step - loss: 0.0076 - val_loss: 0.0397\n",
      "Epoch 46/100\n",
      "426/426 [==============================] - 0s 26us/step - loss: 0.0075 - val_loss: 0.0393\n",
      "Epoch 47/100\n",
      "426/426 [==============================] - 0s 30us/step - loss: 0.0077 - val_loss: 0.0387\n",
      "Epoch 48/100\n",
      "426/426 [==============================] - 0s 27us/step - loss: 0.0076 - val_loss: 0.0410\n",
      "Epoch 49/100\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0075 - val_loss: 0.0396\n",
      "Epoch 50/100\n",
      "426/426 [==============================] - 0s 26us/step - loss: 0.0075 - val_loss: 0.0404\n",
      "Epoch 51/100\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0071 - val_loss: 0.0389\n",
      "Epoch 52/100\n",
      "426/426 [==============================] - 0s 28us/step - loss: 0.0072 - val_loss: 0.0404\n",
      "Epoch 53/100\n",
      "426/426 [==============================] - 0s 25us/step - loss: 0.0073 - val_loss: 0.0392\n",
      "Epoch 54/100\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0073 - val_loss: 0.0398\n",
      "Epoch 55/100\n",
      "426/426 [==============================] - 0s 26us/step - loss: 0.0075 - val_loss: 0.0401\n",
      "Epoch 56/100\n",
      "426/426 [==============================] - 0s 28us/step - loss: 0.0071 - val_loss: 0.0410\n",
      "Epoch 57/100\n",
      "426/426 [==============================] - 0s 26us/step - loss: 0.0072 - val_loss: 0.0395\n",
      "Epoch 58/100\n",
      "426/426 [==============================] - 0s 27us/step - loss: 0.0078 - val_loss: 0.0406\n",
      "Epoch 59/100\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0072 - val_loss: 0.0407\n",
      "Epoch 60/100\n",
      "426/426 [==============================] - 0s 28us/step - loss: 0.0076 - val_loss: 0.0418\n",
      "Epoch 61/100\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0077 - val_loss: 0.0406\n",
      "Epoch 62/100\n",
      "426/426 [==============================] - 0s 31us/step - loss: 0.0071 - val_loss: 0.0412\n",
      "Epoch 63/100\n",
      "426/426 [==============================] - 0s 28us/step - loss: 0.0073 - val_loss: 0.0411\n",
      "Epoch 64/100\n",
      "426/426 [==============================] - 0s 32us/step - loss: 0.0069 - val_loss: 0.0410\n",
      "Epoch 65/100\n",
      "426/426 [==============================] - 0s 28us/step - loss: 0.0068 - val_loss: 0.0420\n",
      "Epoch 66/100\n",
      "426/426 [==============================] - 0s 31us/step - loss: 0.0067 - val_loss: 0.0403\n",
      "Epoch 67/100\n",
      "426/426 [==============================] - 0s 26us/step - loss: 0.0067 - val_loss: 0.0403\n",
      "Epoch 68/100\n",
      "426/426 [==============================] - 0s 31us/step - loss: 0.0070 - val_loss: 0.0407\n",
      "Epoch 69/100\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0071 - val_loss: 0.0402\n",
      "Epoch 70/100\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0067 - val_loss: 0.0407\n",
      "Epoch 71/100\n",
      "426/426 [==============================] - 0s 26us/step - loss: 0.0065 - val_loss: 0.0400\n",
      "Epoch 72/100\n",
      "426/426 [==============================] - 0s 30us/step - loss: 0.0069 - val_loss: 0.0413\n",
      "Epoch 73/100\n",
      "426/426 [==============================] - 0s 27us/step - loss: 0.0065 - val_loss: 0.0421\n",
      "Epoch 74/100\n",
      "426/426 [==============================] - 0s 30us/step - loss: 0.0067 - val_loss: 0.0396\n",
      "Epoch 75/100\n",
      "426/426 [==============================] - 0s 27us/step - loss: 0.0066 - val_loss: 0.0411\n",
      "Epoch 76/100\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0063 - val_loss: 0.0412\n",
      "Epoch 77/100\n",
      "426/426 [==============================] - 0s 30us/step - loss: 0.0066 - val_loss: 0.0413\n",
      "Epoch 78/100\n",
      "426/426 [==============================] - 0s 27us/step - loss: 0.0066 - val_loss: 0.0403\n",
      "Epoch 79/100\n",
      "426/426 [==============================] - 0s 25us/step - loss: 0.0061 - val_loss: 0.0410\n",
      "Epoch 80/100\n",
      "426/426 [==============================] - 0s 28us/step - loss: 0.0067 - val_loss: 0.0403\n",
      "Epoch 81/100\n",
      "426/426 [==============================] - 0s 30us/step - loss: 0.0070 - val_loss: 0.0436\n",
      "Epoch 82/100\n",
      "426/426 [==============================] - 0s 25us/step - loss: 0.0080 - val_loss: 0.0434\n",
      "Epoch 83/100\n",
      "426/426 [==============================] - 0s 26us/step - loss: 0.0074 - val_loss: 0.0397\n",
      "Epoch 84/100\n",
      "426/426 [==============================] - 0s 26us/step - loss: 0.0069 - val_loss: 0.0399\n",
      "Epoch 85/100\n",
      "426/426 [==============================] - 0s 30us/step - loss: 0.0070 - val_loss: 0.0427\n",
      "Epoch 86/100\n",
      "426/426 [==============================] - 0s 27us/step - loss: 0.0068 - val_loss: 0.0407\n",
      "Epoch 87/100\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0066 - val_loss: 0.0406\n",
      "Epoch 88/100\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0066 - val_loss: 0.0414\n",
      "Epoch 89/100\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0069 - val_loss: 0.0422\n",
      "Epoch 90/100\n",
      "426/426 [==============================] - 0s 27us/step - loss: 0.0073 - val_loss: 0.0421\n",
      "Epoch 91/100\n",
      "426/426 [==============================] - 0s 28us/step - loss: 0.0068 - val_loss: 0.0409\n",
      "Epoch 92/100\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0067 - val_loss: 0.0419\n",
      "Epoch 93/100\n",
      "426/426 [==============================] - 0s 32us/step - loss: 0.0074 - val_loss: 0.0420\n",
      "Epoch 94/100\n",
      "426/426 [==============================] - 0s 30us/step - loss: 0.0066 - val_loss: 0.0420\n",
      "Epoch 95/100\n",
      "426/426 [==============================] - 0s 25us/step - loss: 0.0061 - val_loss: 0.0403\n",
      "Epoch 96/100\n",
      "426/426 [==============================] - 0s 28us/step - loss: 0.0061 - val_loss: 0.0415\n",
      "Epoch 97/100\n",
      "426/426 [==============================] - 0s 29us/step - loss: 0.0063 - val_loss: 0.0404\n",
      "Epoch 98/100\n",
      "426/426 [==============================] - 0s 30us/step - loss: 0.0062 - val_loss: 0.0408\n",
      "Epoch 99/100\n",
      "426/426 [==============================] - 0s 27us/step - loss: 0.0061 - val_loss: 0.0407\n",
      "Epoch 100/100\n",
      "426/426 [==============================] - 0s 27us/step - loss: 0.0059 - val_loss: 0.0414\n"
     ]
    }
   ],
   "source": [
    "# Storing that fit as a history log\n",
    "history_log = model.fit(X_train_s, y_train, validation_data=(X_test_s, y_test), epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting our losses\n",
    "#distance on y axis, epochs on x axis\n",
    "train_loss = history_log.history['loss']\n",
    "test_loss = history_log.history['val_loss']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1376d5160>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.plot(test_loss, label='Testing Loss')\n",
    "plt.ylabel('distance')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143, 30)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tensor Tensor(\"dense_2/BiasAdd:0\", shape=(?, 1), dtype=float32) is not an element of this graph.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-57799b1e4c89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_predict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m         return training_arrays.predict_loop(self, f, ins,\n",
      "\u001b[0;32m/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_predict_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    552\u001b[0m                                                \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_updates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m                                                \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'predict_function'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m                                                **kwargs)\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, updates, **kwargs)\u001b[0m\n\u001b[1;32m   2742\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Invalid argument \"%s\" passed to K.function with TensorFlow backend'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2743\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2744\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, updates, name, **session_kwargs)\u001b[0m\n\u001b[1;32m   2544\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2545\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2546\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2547\u001b[0m             \u001b[0mupdates_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2548\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mupdate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcontrol_dependencies\u001b[0;34m(control_inputs)\u001b[0m\n\u001b[1;32m   3593\u001b[0m    \u001b[0moperations\u001b[0m \u001b[0mconstructed\u001b[0m \u001b[0mwithin\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3594\u001b[0m   \"\"\"\n\u001b[0;32m-> 3595\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontrol_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcontrol_dependencies\u001b[0;34m(self, control_inputs)\u001b[0m\n\u001b[1;32m   3322\u001b[0m     \u001b[0mcurrent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3323\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontrol_inputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3324\u001b[0;31m       \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3325\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3326\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2413\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2414\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2416\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2491\u001b[0m       \u001b[0;31m# Actually obj is just the object it's referring to.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2492\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2493\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2494\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2495\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOperation\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor Tensor(\"dense_2/BiasAdd:0\", shape=(?, 1), dtype=float32) is not an element of this graph."
     ]
    }
   ],
   "source": [
    "model.predict(X_test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tensor Tensor(\"dense_2/BiasAdd:0\", shape=(?, 1), dtype=float32) is not an element of this graph.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-a25d014fc6e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m143\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_predict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m         return training_arrays.predict_loop(self, f, ins,\n",
      "\u001b[0;32m/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_predict_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    552\u001b[0m                                                \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_updates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m                                                \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'predict_function'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m                                                **kwargs)\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, updates, **kwargs)\u001b[0m\n\u001b[1;32m   2742\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Invalid argument \"%s\" passed to K.function with TensorFlow backend'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2743\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2744\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, updates, name, **session_kwargs)\u001b[0m\n\u001b[1;32m   2544\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2545\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2546\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2547\u001b[0m             \u001b[0mupdates_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2548\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mupdate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcontrol_dependencies\u001b[0;34m(control_inputs)\u001b[0m\n\u001b[1;32m   3593\u001b[0m    \u001b[0moperations\u001b[0m \u001b[0mconstructed\u001b[0m \u001b[0mwithin\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3594\u001b[0m   \"\"\"\n\u001b[0;32m-> 3595\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontrol_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcontrol_dependencies\u001b[0;34m(self, control_inputs)\u001b[0m\n\u001b[1;32m   3322\u001b[0m     \u001b[0mcurrent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3323\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontrol_inputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3324\u001b[0;31m       \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3325\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3326\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2413\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2414\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2416\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2491\u001b[0m       \u001b[0;31m# Actually obj is just the object it's referring to.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2492\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2493\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2494\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2495\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOperation\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor Tensor(\"dense_2/BiasAdd:0\", shape=(?, 1), dtype=float32) is not an element of this graph."
     ]
    }
   ],
   "source": [
    "np.hstack([model.predict(X_test_s), y_test.reshape(143, 1)])[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 3\n",
    "b = 5\n",
    "c = a + b\n",
    "c \n",
    "# (returns 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "a += 1\n",
    "#let's update a so this flows across the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow as a graph constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing the graph\n",
    "\n",
    "a = tf.Variable(3)\n",
    "b = tf.Variable(5)\n",
    "\n",
    "c = a * b\n",
    "d = a + b * c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting a session\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = sess.run(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    }
   ],
   "source": [
    "# Printing the output\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#suppose we change inputs\n",
    "\n",
    "a = tf.Variable(4)\n",
    "b = tf.Variable(5)\n",
    "\n",
    "c = a + b\n",
    "d = a + b + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = sess.run(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "# Printing the output\n",
    "#should return 49\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 30)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_s.shape\n",
    "#(426, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(dtype=tf.float32, shape=(None, 30))\n",
    "y = tf.placeholder(dtype=tf.float32, shape=(None, 1))\n",
    "\n",
    "hid = tf.layers.dense(X, 30, activation=tf.nn.relu)\n",
    "y_hat = tf.layers.dense(hid, 1, activation=tf.nn.sigmoid)\n",
    "\n",
    "loss = tf.losses.log_loss(y, y_hat)\n",
    "optimizer = tf.train.AdamOptimizer(0.01)\n",
    "training_run = optimizer.minimize(loss)\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.986013986013986"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0.34965034965034963\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for _ in range(100):\n",
    "        sess.run(training_run, feed_dict={X: X_train_s, y: y_train.reshape(-1, 1)})\n",
    "        \n",
    "    pred = sess.run(y_hat, feed_dict={X: X_test_s})\n",
    "\n",
    "classes = (pred > 0.5).astype(int)\n",
    "\n",
    "metrics.accuracy_score(y_test.reshape(-1, 1), classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
